import streamlit as st
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from io import BytesIO
import numpy as np

# Streamlit Title
st.title("🧪 ETL Data Pipeline using Streamlit")

# Upload CSV File
uploaded_file = st.file_uploader("📤 Upload a CSV file", type=["csv"])

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.subheader("📊 Raw Data")
    st.write(df.head())

    # Run ETL Pipeline Button
    if st.button("🚀 Run ETL"):
        try:
            # Identify numeric and categorical columns
            numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
            categorical_cols = df.select_dtypes(include=['object']).columns.tolist()

            # Build transformers
            numeric_transformer = Pipeline(steps=[
                ('imputer', SimpleImputer(strategy='mean')),
                ('scaler', StandardScaler())
            ])

            categorical_transformer = Pipeline(steps=[
                ('imputer', SimpleImputer(strategy='most_frequent')),
                ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
            ])

            # ColumnTransformer (ETL pipeline)
            preprocessor = ColumnTransformer(transformers=[
                ('num', numeric_transformer, numeric_cols),
                ('cat', categorical_transformer, categorical_cols)
            ])

            # Fit the pipeline and transform the data
            transformed_data = preprocessor.fit_transform(df)

            # Get feature names
            cat_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_cols)
            feature_names = numeric_cols + list(cat_feature_names)

            # Create transformed DataFrame
            transformed_df = pd.DataFrame(transformed_data, columns=feature_names)

            # Show transformed data
            st.success("✅ ETL pipeline completed successfully!")
            st.subheader("🧼 Transformed Data")
            st.dataframe(transformed_df.head())

            # Download button
            csv = transformed_df.to_csv(index=False).encode('utf-8')
            st.download_button("📥 Download Transformed Data", csv, file_name="transformed_data.csv", mime="text/csv")

        except Exception as e:
            st.error(f"❌ ETL failed: {str(e)}")
